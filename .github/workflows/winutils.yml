name: Build and Release winutils.exe for Spark

on:
  workflow_dispatch:
    inputs:
      spark_version:
        description: "Spark version (e.g. 3.5.1)"
        required: true
        type: string

permissions:
  contents: write

jobs:
  build:
    runs-on: windows-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Java 8 (required by Hadoop native build)
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: 8

      - name: Setup Maven
        uses: stCarolas/setup-maven@v5
        with:
          maven-version: 3.9.6

      # ------------------------------------------------------------
      # Install Visual Studio (required for native win build)
      # ------------------------------------------------------------
      - name: Install Visual Studio
        run: |
          choco install -y visualstudio2022community --package-parameters "--add Microsoft.VisualStudio.Component.VC.Tools.x86.x64 --add Microsoft.VisualStudio.Component.VC.ATL"

      # ------------------------------------------------------------
      # Validate Spark tag exists and resolve Hadoop version
      # ------------------------------------------------------------
      - name: Resolve Hadoop version from Spark POM
        shell: bash
        run: |
          set -e

          SPARK_VERSION="${{ inputs.spark_version }}"
          SPARK_POM_URL="https://raw.githubusercontent.com/apache/spark/v${SPARK_VERSION}/pom.xml"

          echo "Fetching Spark POM: $SPARK_POM_URL"
          curl -f -L "$SPARK_POM_URL" -o spark-pom.xml

          HADOOP_VERSION=$(xmllint --xpath \
            "string(//*[local-name()='properties']/*[local-name()='hadoop.version']/text())" \
            spark-pom.xml)

          if [ -z "$HADOOP_VERSION" ]; then
            echo "Failed to resolve Hadoop version from Spark ${SPARK_VERSION}"
            exit 1
          fi

          echo "Resolved Hadoop version: $HADOOP_VERSION"
          echo "HADOOP_VERSION=$HADOOP_VERSION" >> $GITHUB_ENV

      # ------------------------------------------------------------
      # Download Hadoop source (fail fast if wrong)
      # ------------------------------------------------------------
      - name: Download Hadoop source
        shell: bash
        run: |
          set -e

          HADOOP_VERSION="${HADOOP_VERSION}"
          HADOOP_URL="https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}-src.tar.gz"

          echo "Downloading Hadoop source: $HADOOP_URL"
          curl -f -L -o hadoop-src.tar.gz "$HADOOP_URL"

          # Fail fast if we downloaded HTML or garbage
          file hadoop-src.tar.gz
          test "$(stat -c%s hadoop-src.tar.gz)" -gt 1000000

          tar -xzf hadoop-src.tar.gz

      # ------------------------------------------------------------
      # Build winutils.exe using msbuild on the winutils solution
      # ------------------------------------------------------------
      - name: Build winutils.exe
        shell: cmd
        run: |
          call "C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Auxiliary\Build\vcvarsall.bat" amd64
          cd hadoop-%HADOOP_VERSION%-src\hadoop-common-project\hadoop-common\src\main\winutils
          :: Patch GetFileInformationByName conflict with Windows SDK 10.0.26100+
          powershell -Command "(Get-ChildItem -Recurse -Filter '*.c' -Name) | ForEach-Object { (Get-Content $_) -replace 'GetFileInformationByName','HadoopGetFileInformationByName' | Set-Content $_ }"
          powershell -Command "(Get-ChildItem -Recurse -Filter '*.h' -Name) | ForEach-Object { (Get-Content $_) -replace 'GetFileInformationByName','HadoopGetFileInformationByName' | Set-Content $_ }"
          msbuild winutils.sln /p:Configuration=Release /p:Platform=x64 /p:PlatformToolset=v143 /p:WsceConfigDir="../etc/config" /p:WsceConfigFile="wsce-site.xml"

      # ------------------------------------------------------------
      # Build hadoop.dll native library
      # ------------------------------------------------------------
      - name: Build hadoop.dll
        shell: cmd
        run: |
          call "C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Auxiliary\Build\vcvarsall.bat" amd64
          cd hadoop-%HADOOP_VERSION%-src\hadoop-common-project\hadoop-common\src\main\native
          msbuild native.sln /p:Configuration=Release /p:Platform=x64 /p:PlatformToolset=v143

      # ------------------------------------------------------------
      # Prepare artifact with all native files
      # ------------------------------------------------------------
      - name: Prepare winutils artifact
        shell: bash
        run: |
          mkdir -p dist/bin
          # Copy winutils files
          cp hadoop-${HADOOP_VERSION}-src/hadoop-common-project/hadoop-common/src/main/winutils/x64/Release/*.exe dist/bin/ 2>/dev/null || true
          cp hadoop-${HADOOP_VERSION}-src/hadoop-common-project/hadoop-common/src/main/winutils/x64/Release/*.lib dist/bin/ 2>/dev/null || true
          # Copy hadoop native files
          cp hadoop-${HADOOP_VERSION}-src/hadoop-common-project/hadoop-common/src/main/native/native/*.dll dist/bin/ 2>/dev/null || true
          cp hadoop-${HADOOP_VERSION}-src/hadoop-common-project/hadoop-common/src/main/native/native/*.lib dist/bin/ 2>/dev/null || true

      # ------------------------------------------------------------
      # Release handling (overwrite if exists)
      # ------------------------------------------------------------
      - name: Delete existing release (if any)
        shell: bash
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh release delete winutils-${HADOOP_VERSION} --yes || true

      - name: Create GitHub release
        shell: bash
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh release create winutils-${HADOOP_VERSION} \
            dist/bin/* \
            --title "winutils for Spark ${{ inputs.spark_version }}" \
            --notes "Native binaries built from Hadoop ${HADOOP_VERSION}, as required by Spark ${{ inputs.spark_version }}"
